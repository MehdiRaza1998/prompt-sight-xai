# -*- coding: utf-8 -*-
"""t5_text_to_sql_SHAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13QsGwB_347ZBlLUh2YuxIXkNYSg0S8mr
"""

pip install shap

from typing import List
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import shap
import numpy as np

# Load the tokenizer and model from Hugging Face
tokenizer = AutoTokenizer.from_pretrained("juierror/text-to-sql-with-table-schema")
model = AutoModelForSeq2SeqLM.from_pretrained("juierror/text-to-sql-with-table-schema")
shap_values_global = []

from typing import List
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import shap
import numpy as np

# Load the tokenizer and model from Hugging Face
tokenizer = AutoTokenizer.from_pretrained("juierror/text-to-sql-with-table-schema")
model = AutoModelForSeq2SeqLM.from_pretrained("juierror/text-to-sql-with-table-schema")
shap_values_global = []

def prepare_input(question: str, table: List[str]):
    table_prefix = "table:"
    question_prefix = "question:"
    join_table = ",".join(table)
    inputs = f"{question_prefix} {question} {table_prefix} {join_table}"
    input_ids = tokenizer(inputs, max_length=700, return_tensors="pt").input_ids
    return input_ids

def inference_with_logits(question: str, table: List[str]) -> tuple:
    input_data = prepare_input(question=question, table=table)
    input_data = input_data.to(model.device)
    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=700, return_dict_in_generate=True, output_scores=True)
    result = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)
    logits = outputs.sequences_scores[0]
    return result, logits

def shap_explain(question: str, table: List[str]):
    # Define a function that takes a list of questions and returns the logits
    def predict_logits(questions):
        logits_list = []
        for q in questions:
            _, logits = inference_with_logits(q, table)
            logits_list.append(logits.detach().cpu().numpy())
        return np.array(logits_list)

    # Create a SHAP explainer
    explainer = shap.Explainer(predict_logits, tokenizer)

    # Explain the prediction for the given question
    shap_values = explainer([question])
    shap_values_global= shap_values
    # Plot the SHAP values
    shap.plots.text(shap_values)
    print(shap_values)



# Example usage
schema = ["id", "name", "age", "location"]
query = "get people name with age greater than 25 and name is mehdi and lives in karachi"

# SHAP explanation
shap_explain(query, schema)

# Plot the SHAP values
import shap
import numpy as np
import matplotlib.pyplot as plt

# Provided SHAP values
shap_values_data = np.array([[0.00449876, 0.00210243, 0.04338298, 0.01489573, 0.02066969,
                              -0.01511856, -0.00276532, 0.01518595, -0.00429825, 0.01394496,
                              0.00247532, 0.00277105, 0.00137094, 0.00101049, 0.00242654,
                              0.00138322, 0.00371006, 0.00577482, 0.00550716, 0.0041081,
                              0.00929278, 0.0]])

base_values = np.array([-0.1539432])
data = np.array(['get ', 'people ', 'name ', 'with ', 'age ', 'greater ', 'than ',
                 '25 ', 'and ', 'name ', 'is ', 'me', 'h', 'd', 'i ', 'and ',
                 'lives ', 'in ', 'k', 'kar', 'achi', ''], dtype=object).reshape(1, -1)

# Create a SHAP values object
shap_values = shap.Explanation(values=shap_values_data, base_values=base_values, data=data, feature_names=data[0])

# Plotting
shap.plots.bar(shap_values)  # Bar plot
shap.plots.beeswarm(shap_values)  # Summary plot
shap.plots.waterfall(shap_values[0])  # Waterfall plot